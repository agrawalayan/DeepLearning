{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_ShKODI5URp"
   },
   "outputs": [],
   "source": [
    "#Deep Learning Assignment 1 - Part 2\n",
    "#Joshua Abraham - jma672\n",
    "#Ayan Agrawal - aka398"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oqZ3S6XWn7z"
   },
   "outputs": [],
   "source": [
    "#installation of the pytorch library\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip3 install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4leS4SUWzJO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Y72709w-W9Kv",
    "outputId": "c595e5e6-e2c1-4d42-8617-db7c43c88c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#downloading the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./cifardata', train=True, download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./cifardata', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hv1Kxh8JXDfj"
   },
   "outputs": [],
   "source": [
    "#dividinng the train set into 9:1 to perform training and validation\n",
    "#based on the validation loss we are tuning the hyperparameters\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_samples = 45000\n",
    "trainData = SubsetRandomSampler(np.arange(train_samples, dtype=np.int64))\n",
    "\n",
    "validation_samples = 5000\n",
    "validationData = SubsetRandomSampler(np.arange(train_samples, train_samples + validation_samples, dtype=np.int64))\n",
    "\n",
    "test_samples = 10000\n",
    "testData = SubsetRandomSampler(np.arange(test_samples, dtype=np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1poHRtiXsBh"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ####################Architecture##################\n",
    "        #original_image --> conv_1 -->max_pool-->conv_2-->max_pool-->conv3-->FC Layer1-->FC2--FC2\n",
    "        ##################################################\n",
    "        \n",
    "        #original image size is 32*32*3\n",
    "        #first layer of convolution\n",
    "        #in_channel=3,out_channel=36,#kernel_size=3*3,stride=1,padding=1\n",
    "        #with just having one convolution layer he accuracy came out to be 66%\n",
    "        #thus we increased the convolutional layers to 3 to match the validation loss with the train loss approximately\n",
    "        self.conv1 = nn.Conv2d(3, 36, 3, 1, padding=1) #66%\n",
    "        #max pool layer of 2*2 with stride=2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        #in_channel=36,out_channel=144,#kernel_size=3*3,stride=1,padding=1\n",
    "        self.conv2 = nn.Conv2d(36, 144, 3,1,padding=1)\n",
    "        #in_channel=144,out_channel=288,#kernel_size=3*3,stride=1,padding=1\n",
    "        self.conv3 = nn.Conv2d(144, 288, 3,1,padding=1)\n",
    "        #the image size input to the fully connected layer is now 8*8 after conv and max_pool\n",
    "        #288 is the number of input hidden units\n",
    "        self.fc1 = nn.Linear(288 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x= self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #x = self.pool()\n",
    "        #flatten the input input image\n",
    "        x = x.view(-1, 288 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cwj6UdN9X-Mb"
   },
   "outputs": [],
   "source": [
    "#def outputSize(in_size, kernel_size, stride, padding):\n",
    "\n",
    "#  output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
    "\n",
    "#  return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0oNA1bnYSRT"
   },
   "outputs": [],
   "source": [
    "def get_train_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                           sampler=trainData, num_workers=2)\n",
    "    return(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TariiOVqYcsa"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=validationData, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, sampler=testData, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHBTVqUcYhbc"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def LossOptimizerFunction(net, learning_rate=0.001):\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    return(loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBDaNpKFYqrx"
   },
   "outputs": [],
   "source": [
    "def train(net, batch_size, learning_rate,epochs):\n",
    "    #Load the training data\n",
    "    train_loader = get_train_loader(batch_size)\n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    #Call the loss and optimizer functions\n",
    "    loss, optimizer = LossOptimizerFunction(net, learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            image_input, labels = data\n",
    "            \n",
    "            #Make a variable object wrapper\n",
    "            image_input, labels = Variable(image_input), Variable(labels)\n",
    "            \n",
    "            #initialize the gradient parameters to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward propogation\n",
    "            outputs = net(image_input)\n",
    "            #calculate the loss\n",
    "            loss_size = loss(outputs, labels)\n",
    "            #Backward propogation\n",
    "            loss_size.backward()\n",
    "            #Optimizer usage\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            running_loss += loss_size.data[0]\n",
    "            \n",
    "            #Print every 10th batch of an epoch\n",
    "            if (i + 1) % (print_every + 1) == 0:\n",
    "                print(\"Epoch {}, Train_Loss: {:.2f}\".format(\n",
    "                        epoch+1, running_loss / print_every))\n",
    "                #Reset running loss and time\n",
    "                running_loss = 0.0\n",
    "            \n",
    "        #Calculate the validation loss\n",
    "        total_validation_loss = 0\n",
    "        for image_inputs, labels in val_loader:\n",
    "            \n",
    "            #Make a variable object wrapper\n",
    "            image_inputs, labels = Variable(image_inputs), Variable(labels)\n",
    "            \n",
    "            #To calculate the loss on validation we require just the Forward propogation\n",
    "            val_outputs = net(image_inputs)\n",
    "            val_loss_size = loss(val_outputs, labels)\n",
    "            total_validation_loss += val_loss_size.data[0]\n",
    "            \n",
    "        print(\"Validation loss = {:.2f}\".format(total_validation_loss / len(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "colab_type": "code",
    "id": "c1mCHMvHYvFz",
    "outputId": "0bb93578-e205-43e3-b83a-322a01dfa308"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train_Loss: 2.00\n",
      "Epoch 1, Train_Loss: 1.65\n",
      "Epoch 1, Train_Loss: 1.46\n",
      "Epoch 1, Train_Loss: 1.36\n",
      "Epoch 1, Train_Loss: 1.29\n",
      "Epoch 1, Train_Loss: 1.25\n",
      "Epoch 1, Train_Loss: 1.21\n",
      "Epoch 1, Train_Loss: 1.16\n",
      "Epoch 1, Train_Loss: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss = 1.02\n",
      "Epoch 2, Train_Loss: 0.99\n",
      "Epoch 2, Train_Loss: 0.97\n",
      "Epoch 2, Train_Loss: 0.96\n",
      "Epoch 2, Train_Loss: 0.95\n",
      "Epoch 2, Train_Loss: 0.91\n",
      "Epoch 2, Train_Loss: 0.92\n",
      "Epoch 2, Train_Loss: 0.92\n",
      "Epoch 2, Train_Loss: 0.85\n",
      "Epoch 2, Train_Loss: 0.86\n",
      "Validation loss = 0.86\n",
      "Epoch 3, Train_Loss: 0.71\n",
      "Epoch 3, Train_Loss: 0.72\n",
      "Epoch 3, Train_Loss: 0.74\n",
      "Epoch 3, Train_Loss: 0.71\n",
      "Epoch 3, Train_Loss: 0.69\n",
      "Epoch 3, Train_Loss: 0.74\n",
      "Epoch 3, Train_Loss: 0.72\n",
      "Epoch 3, Train_Loss: 0.68\n",
      "Epoch 3, Train_Loss: 0.71\n",
      "Validation loss = 0.75\n",
      "Epoch 4, Train_Loss: 0.55\n",
      "Epoch 4, Train_Loss: 0.57\n",
      "Epoch 4, Train_Loss: 0.55\n",
      "Epoch 4, Train_Loss: 0.55\n",
      "Epoch 4, Train_Loss: 0.54\n",
      "Epoch 4, Train_Loss: 0.56\n",
      "Epoch 4, Train_Loss: 0.60\n",
      "Epoch 4, Train_Loss: 0.56\n",
      "Epoch 4, Train_Loss: 0.56\n",
      "Validation loss = 0.70\n",
      "Epoch 5, Train_Loss: 0.37\n",
      "Epoch 5, Train_Loss: 0.41\n",
      "Epoch 5, Train_Loss: 0.41\n",
      "Epoch 5, Train_Loss: 0.42\n",
      "Epoch 5, Train_Loss: 0.42\n",
      "Epoch 5, Train_Loss: 0.43\n",
      "Epoch 5, Train_Loss: 0.44\n",
      "Epoch 5, Train_Loss: 0.42\n",
      "Epoch 5, Train_Loss: 0.44\n",
      "Validation loss = 0.77\n"
     ]
    }
   ],
   "source": [
    "CNN = CNN()\n",
    "train(CNN, 32, 0.001,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "h_pOwFnYZqBd",
    "outputId": "be696753-b367-41e2-d0fb-ae6f442f60f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy == 73 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "predicted_labels = []\n",
    "#for prediction there is no need of storing the gradients\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = CNN(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        predicted_labels.append(predicted)\n",
    "print('Accuracy == %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HeMFbiUpWTTB"
   },
   "outputs": [],
   "source": [
    "def savepredictions(filename,y):\n",
    "  np.save(filename,y)\n",
    "predicted_values = []\n",
    "for batch_labels in predicted_labels:\n",
    "  for images in batch_labels:\n",
    "    predicted_values.append(images)\n",
    "\n",
    "\n",
    "savepredictions(\"ans2-aka398.npy\",predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_TFPbO-5p2Uj",
    "outputId": "25eb0fa3-bccf-4f15-aeb6-4b0a86606b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"ans2-aka398.npy\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_G_vwbUoXLD6"
   },
   "source": [
    "1) We started with one convolutional layer, 3 fully connected layer and number of epoch as 2. We kept the optimizer as \"SGD\". We got an accuracy of 7%. Also, we observed that there was a marginable differnce between the validation loss and the train loss. So we decided to increase the number of epochs considering that it requires more time to train.\n",
    "\n",
    "2) We increased the number of epochs to 5. Our accuracy came out to be 54%. We observed that the validation loss was 1.24 and the train loss was 0.74. Such a large difference indicated that our model was overfitting the train data. We dicided to to go with other optimizer as \"Adam\" and removed the momentum parameter from the argument.\n",
    "\n",
    "3) Rest all we kept as it is and started training. We got an accuracy of 62%. Now the difference between the train loss and validation loss reduced but it was still not satisfactory.\n",
    "\n",
    "4) But we noticed that using Adam Optimizer was beneficial since it is a combination of both Momentum and RMS prop.\n",
    "\n",
    "5) Then we increased the convolutional layer to 3. Change the number of filters, added the padding argument. We observed that at epoch number of approximately 3 and 4 we were getting matching values of train loss and validation loss. So we decided to stay with this hyperparameters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1-CNN-uni.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
